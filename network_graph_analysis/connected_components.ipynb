{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weakly Connected Components und Strongly Connected Components von Neo4j"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WCC: Identifiziert Gruppen von Knoten in einem ungerichteten Graphen, die durch Pfade miteinander verbunden sind, unabhängig von der Richtung der Beziehungen. <br>\n",
    "SCC: Identifiziert Gruppen von Knoten in einem gerichteten Graphen, in dem für jedes Knotenpaar in der Gruppe ein Pfad von jedem Knoten zum anderen existiert, wobei die Richtung der Beziehungen berücksichtigt wird. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'account': 'A1', 'componentId': 0}\n",
      "{'account': 'A2', 'componentId': 0}\n",
      "{'account': 'A3', 'componentId': 0}\n",
      "{'account': 'A4', 'componentId': 0}\n",
      "{'account': 'A5', 'componentId': 0}\n"
     ]
    }
   ],
   "source": [
    "from py2neo import Graph\n",
    "\n",
    "graph = Graph(\"bolt://localhost:7687\", auth=(\"neo4j\", \"\")) \n",
    "\n",
    "# Cypher-Abfrage für den WCC Algorithmus\n",
    "wcc_query = \"\"\"\n",
    "CALL gds.wcc.stream('graphAcc20')\n",
    "YIELD nodeId, componentId\n",
    "RETURN gds.util.asNode(nodeId).accountNumber AS account, componentId\n",
    "ORDER BY componentId\n",
    "\"\"\"\n",
    "\n",
    "results = graph.run(wcc_query).data()\n",
    "\n",
    "for result in results:\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "class OpenAIWrapper:\n",
    "    def __init__(self, api_key):\n",
    "        self.api_key = api_key\n",
    "        openai.api_key = self.api_key\n",
    "\n",
    "    def generate_chat_response(self, prompt, model=\"gpt-3.5-turbo\", temperature=0.7, max_tokens=150):\n",
    "        try:\n",
    "            response = openai.ChatCompletion.create(\n",
    "                model=model,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "                    {\"role\": \"user\", \"content\": prompt}\n",
    "                ],\n",
    "                temperature=temperature,\n",
    "                max_tokens=max_tokens\n",
    "            )\n",
    "            return response.choices[0].message['content'].strip() \n",
    "        except Exception as e:\n",
    "            return f\"An error occurred: {str(e)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the following weakly connected components analysis of a network, where every person is connected to every other person through some path:\n",
      "\n",
      "A1 is in component 0\n",
      "A2 is in component 0\n",
      "A3 is in component 0\n",
      "A4 is in component 0\n",
      "A5 is in component 0\n",
      "\n",
      "What insights can we derive from this complete connectivity? What might be the implications for information flow or social dynamics within this network?\n",
      "GPT-3's Insights: An error occurred: You didn't provide an API key. You need to provide your API key in an Authorization header using Bearer auth (i.e. Authorization: Bearer YOUR_KEY), or as the password field (with blank username) if you're accessing the API from your browser and are prompted for a username and password. You can obtain an API key from https://platform.openai.com/account/api-keys.\n"
     ]
    }
   ],
   "source": [
    "openai_wrapper = OpenAIWrapper(api_key='')\n",
    "\n",
    "prompt_intro = \"Based on the following weakly connected components analysis of a network, where every person is connected to every other person through some path:\\n\\n\"\n",
    "\n",
    "prompt_body = \"\\n\".join([f\"{res['account']} is in component {res['componentId']}\" for res in results])\n",
    "\n",
    "prompt_questions = \"\\n\\nWhat insights can we derive from this complete connectivity? What might be the implications for information flow or social dynamics within this network?\"\n",
    "\n",
    "complete_prompt = prompt_intro + prompt_body + prompt_questions\n",
    "\n",
    "print(complete_prompt)\n",
    "\n",
    "response = openai_wrapper.generate_chat_response(complete_prompt)\n",
    "print(f\"GPT-3's Insights: {response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'account': 'A1', 'componentId': 0}\n",
      "{'account': 'A2', 'componentId': 0}\n",
      "{'account': 'A3', 'componentId': 0}\n",
      "{'account': 'A4', 'componentId': 0}\n",
      "{'account': 'A5', 'componentId': 0}\n"
     ]
    }
   ],
   "source": [
    "scc_query = \"\"\"\n",
    "CALL gds.alpha.scc.stream('graphAcc20')\n",
    "YIELD nodeId, componentId\n",
    "RETURN gds.util.asNode(nodeId).accountNumber AS account, componentId\n",
    "ORDER BY componentId\n",
    "\"\"\"\n",
    "\n",
    "results = graph.run(scc_query).data()\n",
    "\n",
    "for result in results:\n",
    "    print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output Deutung: <br>\n",
    "alle Knoten dieselbe componentId (0) für beide Algorithmen haben, deutet dies darauf hin, dass Ihr Graph im Kontext von WCC als vollständig verbunden betrachtet wird. <br>\n",
    "Für SCC bedeutet es, dass, trotz der Berücksichtigung der Richtung der Beziehungen, immer noch jeder Knoten von jedem anderen Knoten aus erreichbar ist. Dies zeigt eine starke interne Vernetzung <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the analysis of strongly connected components in the network, where each person can reach every other person through a directed path, the following connections were identified:\n",
      "\n",
      "A1 is in strongly connected component 0\n",
      "A2 is in strongly connected component 0\n",
      "A3 is in strongly connected component 0\n",
      "A4 is in strongly connected component 0\n",
      "A5 is in strongly connected component 0\n",
      "\n",
      "Considering this strong interconnectivity, what can be inferred about the network's resilience and potential points of failure? Additionally, how might this connectivity influence the spread of information or behaviors within the network?\n",
      "GPT-3's Insights: An error occurred: You didn't provide an API key. You need to provide your API key in an Authorization header using Bearer auth (i.e. Authorization: Bearer YOUR_KEY), or as the password field (with blank username) if you're accessing the API from your browser and are prompted for a username and password. You can obtain an API key from https://platform.openai.com/account/api-keys.\n"
     ]
    }
   ],
   "source": [
    "prompt_intro = \"Based on the analysis of strongly connected components in the network, where each person can reach every other person through a directed path, the following connections were identified:\\n\\n\"\n",
    "\n",
    "# Die Ergebnisse in einen lesbaren Text umwandeln\n",
    "prompt_body = \"\\n\".join([f\"{res['account']} is in strongly connected component {res['componentId']}\" for res in results])\n",
    "\n",
    "prompt_questions = \"\\n\\nConsidering this strong interconnectivity, what can be inferred about the network's resilience and potential points of failure? Additionally, how might this connectivity influence the spread of information or behaviors within the network?\"\n",
    "\n",
    "complete_prompt = prompt_intro + prompt_body + prompt_questions\n",
    "\n",
    "print(complete_prompt)\n",
    "\n",
    "response = openai_wrapper.generate_chat_response(complete_prompt)\n",
    "print(f\"GPT-3's Insights: {response}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
